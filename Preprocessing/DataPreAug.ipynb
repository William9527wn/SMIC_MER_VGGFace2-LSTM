{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on Monday May 25 10:51 2020\n",
    "Used to pre-process dataset \n",
    "@author: Keira - github.com/Keira. Bai\n",
    "a.function to divide data set into 5 groups for cross-validation, return a 5*N dimention matrix \n",
    "b.function to extract training data into fixed size sequences, sequences consist by consecuous internal\n",
    "c.function to extract validation data, sequences consist by raw image and adding frames to the same size\n",
    "d.function to read image\n",
    "\"\"\"\n",
    "#Data preprocessing version 2.0\n",
    "#1. Random steps between frames within a slide window;\n",
    "#2. Fixed-size of slide window(Can't be implemented on seleframe != 11);\n",
    "#3. No flipping\n",
    "#4. Raw data for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import PIL\n",
    "import torch\n",
    "import glob as gb\n",
    "import numpy as np\n",
    "from torch.utils import data\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CrossAllocation(datapaths,k):\n",
    "    neg_dir = \"*/negative/*\"\n",
    "    pos_dir = \"*/positive/*\"\n",
    "    sur_dir = \"*/surprise/*\"\n",
    "    non_dir = \"non_micro/*\"\n",
    "    imgpath = \"/*.bmp\"\n",
    "    sequ_list = []\n",
    "    label_list = []\n",
    "    Val_tra_tes_list = []\n",
    "    label = 0\n",
    "    #   Load in all folders adding expression\n",
    "    for vid_dir in [neg_dir, pos_dir, sur_dir, non_dir]:        \n",
    "        sequ = gb.glob(datapaths+vid_dir)\n",
    "        sequ_list += sequ\n",
    "        label_list += [label for i in range(len(sequ))]\n",
    "        label += 1\n",
    "    #Devide All Data into 5 groups\n",
    "    for i in range(k):\n",
    "        if k-i>1:\n",
    "            train_list, valid_list, train_label, valid_label = train_test_split(sequ_list, label_list, \\\n",
    "                                          test_size=1/(k-i), random_state=42)\n",
    "            Val_tra_tes_list.append([valid_list, valid_label])\n",
    "            \n",
    "        else:\n",
    "            Val_tra_tes_list.append([train_list, train_label])\n",
    "\n",
    "        sequ_list = train_list\n",
    "        label_list = train_label   \n",
    "\n",
    "    return Val_tra_tes_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def InputImagewithSlide(tra_tes_list, seleframe = 11):    \n",
    "    imgpath = \"/*.bmp\"\n",
    "    sequ_list = []\n",
    "    \n",
    "    exp_list = []\n",
    "    step_list = [1,2,3,4,5,6]\n",
    "    expCount = [0,0,0,0,0,0,0,0]\n",
    "\n",
    "    for group in tra_tes_list:    \n",
    "        for folder, exp in zip(group[0], group[1]):\n",
    "            img_list = sorted(gb.glob(folder + imgpath))\n",
    "            img_len = len(img_list)\n",
    "            expCount[exp] += img_len\n",
    "            #control step to keep the amout balance between expressions\n",
    "            if exp == 3:\n",
    "                step = 3\n",
    "            else:\n",
    "                step = 1\n",
    "            for i in range(0, img_len-seleframe+step, step):\n",
    "                    if ((img_len-i) >= (seleframe+step-1)):#sequence is enough for a seleframe+step\n",
    "                        for s in step_list:#assign inner step for frame\n",
    "                            if img_len-i >= seleframe*s:\n",
    "                                sequence = []\n",
    "                                for j in range(0,seleframe*s,s):\n",
    "                                    sequence.append(img_list[j+i]) #frames for a window size  \n",
    "                                sequ_list.append(sequence)#adding sequence for sequence list\n",
    "                                exp_list.append(exp)\n",
    "                                expCount[exp+4] += seleframe#After sliding\n",
    "                    else:\n",
    "                        if step != 1:\n",
    "                            m = img_len-seleframe\n",
    "                            sequence = []\n",
    "                            for j in range(seleframe):\n",
    "                                sequence.append(img_list[j+m])#frames for a window size \n",
    "                            sequ_list.append(sequence)\n",
    "                            exp_list.append(exp)\n",
    "                            expCount[exp+4] += seleframe\n",
    "\n",
    "    return sequ_list, exp_list, expCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence list shape:[ 9098 , 11 ]\n",
      "sequence label shape:[ 9098 ]\n",
      "Amount of each expression before sliding: [2216, 1848, 1463, 5103]\n",
      "Amount of each expression after sliding: [28501, 27720, 19877, 23980]\n"
     ]
    }
   ],
   "source": [
    "def RawforVal(val):\n",
    "    imgpath = \"/*.bmp\"\n",
    "    sequ_list = []\n",
    "    exp_list = []\n",
    "    expCount = [0,0,0,0]      \n",
    "    \n",
    "    for folder, exp in zip(val[0],val[1]):      \n",
    "        img_list = sorted(gb.glob(folder + imgpath))\n",
    "        img_len = len(img_list)\n",
    "        expCount[exp] += img_len\n",
    "        sequ_list.append(img_list)\n",
    "        exp_list.append(exp)\n",
    "    return sequ_list, exp_list, expCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on Saturday April 13 10:51 2020\n",
    "Used for data preprocessing without augmentation \n",
    "@author: Keira - github.com/Keira. Bai\n",
    "\"\"\"\n",
    "class MicroExpDataset(data.Dataset):\n",
    "    \"\"\"Micro Expressions dataset.\"\"\" \n",
    "\n",
    "    def __init__(self, folders, labels, tran_t = None, tran_r = None):\n",
    "        \n",
    "        self.tran_t = tran_t\n",
    "        self.folders = folders\n",
    "        self.labels = labels\n",
    "        sequ_list = []\n",
    "        exp_list = []\n",
    "        exp = 0\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.folders)         \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.folders[idx]\n",
    "        exp = torch.LongTensor([self.labels[idx]])\n",
    "        sample = []\n",
    "        for i in seq:\n",
    "            img = mpimg.imread(i)  \n",
    "            img = Image.fromarray(img)\n",
    "            img0 = self.tran_t(img) #original image\n",
    "            sample.append(img0)\n",
    "        sample = torch.stack(sample, dim=0) \n",
    "        return sample, exp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
